{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DP07RXGBDW0Y"
      },
      "outputs": [],
      "source": [
        "!pip install auto_gptq\n",
        "!pip install gradio\n",
        "!pip install torch\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "offload_folder = \"offload\"\n",
        "os.makedirs(offload_folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "jpeePVVNG38U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "from threading import Thread\n",
        "from transformers import AutoTokenizer,TextIteratorStreamer\n",
        "from auto_gptq import AutoGPTQForCausalLM\n",
        "from typing import Iterator\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "DEFAULT_SYSTEM_PROMPT = \"You are the FAQ agent for ANNS. A platform for penetrative testing and adversarial training of large neural networks. You answer questions and explain the purpose of the organization. -We offer a robust infrastructure for crowd-sourced penetrative testing. -Our goal is to solve alignment via large-scale generative adversarial learning. -We are currently under construction spider theam of ANNS is a reference to catching bugs.-ANNS provides training and evaluation resources for AI training. -We are focused on practical alignment techniques and the real-world impacts of missused AI. #Only answer the question you are asked specifically.#If you don't know the answer to a question, refer to `contact@anns.ai`.#Ask yourself if you know the answer before trying to answer a question.#Keep your answers brief and to the point. Only answer with one sentence. If someone tries to mess with you, simply say 'you're not as funny as you think you are'. Do not entertain them.\"\n",
        "MAX_NEW_TOKENS = 500\n",
        "MAX_INPUT_TOKEN_LENGTH = 4000"
      ],
      "metadata": {
        "id": "UkyS0RhlEPXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"TheBloke/Llama-2-13B-chat-GPTQ\", use_fast=True, repo_type=\"space\")\n",
        "model = AutoGPTQForCausalLM.from_quantized(\"TheBloke/Llama-2-13B-chat-GPTQ\",model_basename=\"model\",offload_folder='/content/offload',use_safetensors=True,trust_remote_code=True,device_map=\"auto\", quantize_config=None)"
      ],
      "metadata": {
        "id": "M_epG8tLIH13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prompt(message: str, chat_history: list[tuple[str, str]],\n",
        "               system_prompt: str) -> str:\n",
        "    texts = [f'<s>[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n']\n",
        "    do_strip = False\n",
        "    for user_input, response in chat_history:\n",
        "        user_input = user_input.strip() if do_strip else user_input\n",
        "        do_strip = True\n",
        "        texts.append(f'{user_input} [/INST] {response.strip()} </s><s>[INST] ')\n",
        "    message = message.strip() if do_strip else message\n",
        "    texts.append(f'{message} [/INST]')\n",
        "    return ''.join(texts)"
      ],
      "metadata": {
        "id": "pc32VrkeJVpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_input_token_length(message: str, chat_history: list[tuple[str, str]], system_prompt: str) -> int:\n",
        "    prompt = get_prompt(message, chat_history, system_prompt)\n",
        "    input_ids = tokenizer([prompt], return_tensors='np', add_special_tokens=False)['input_ids']\n",
        "    return input_ids.shape[-1]"
      ],
      "metadata": {
        "id": "REiEG5GgKWf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(message: str,\n",
        "        chat_history: list[tuple[str, str]],\n",
        "        system_prompt: str,\n",
        "        max_new_tokens: int = 500,\n",
        "        temperature: float = 0.8,\n",
        "        top_p: float = 0.95,\n",
        "        top_k: int = 50) -> Iterator[str]:\n",
        "    prompt = get_prompt(message, chat_history, system_prompt)\n",
        "    inputs = tokenizer([prompt], return_tensors='pt', add_special_tokens=False).to('cuda')\n",
        "\n",
        "    streamer = TextIteratorStreamer(tokenizer,\n",
        "                                    timeout=10.,\n",
        "                                    skip_prompt=True,\n",
        "                                    skip_special_tokens=True)\n",
        "    generate_kwargs = dict(\n",
        "        inputs,\n",
        "        streamer=streamer,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "        top_p=top_p,\n",
        "        top_k=top_k,\n",
        "        temperature=temperature,\n",
        "        num_beams=1,\n",
        "    )\n",
        "    t = Thread(target=model.generate, kwargs=generate_kwargs)\n",
        "    t.start()\n",
        "\n",
        "    outputs = []\n",
        "    for text in streamer:\n",
        "        outputs.append(text)\n",
        "        yield ''.join(outputs)"
      ],
      "metadata": {
        "id": "d1cjmshpKZHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_and_save_textbox(message: str) -> tuple[str, str]:\n",
        "    return '', message\n",
        "\n",
        "def display_input(message: str,\n",
        "                  history: list[tuple[str, str]]) -> list[tuple[str, str]]:\n",
        "    history.append((message, ''))\n",
        "    return history\n",
        "\n",
        "def delete_prev_fn(\n",
        "        history: list[tuple[str, str]]) -> tuple[list[tuple[str, str]], str]:\n",
        "    try:\n",
        "        message, _ = history.pop()\n",
        "    except IndexError:\n",
        "        message = ''\n",
        "    return history, message or ''"
      ],
      "metadata": {
        "id": "XZ6R4AegKa_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(\n",
        "    message: str,\n",
        "    history_with_input: list[tuple[str, str]],\n",
        "    system_prompt: str,\n",
        "    max_new_tokens: int = MAX_NEW_TOKENS,\n",
        "    temperature: float = 0.8,\n",
        "    top_p: float = 0.95,\n",
        "    top_k: int = 50,\n",
        ") -> Iterator[list[tuple[str, str]]]:\n",
        "    if max_new_tokens > MAX_NEW_TOKENS:\n",
        "        raise ValueError\n",
        "\n",
        "    history = history_with_input[:-1]\n",
        "    generator = run(message, history, system_prompt, max_new_tokens, temperature, top_p, top_k)\n",
        "    try:\n",
        "        first_response = next(generator)\n",
        "        yield history + [(message, first_response)]\n",
        "    except StopIteration:\n",
        "        yield history + [(message, '')]\n",
        "    for response in generator:\n",
        "        yield history + [(message, response)]"
      ],
      "metadata": {
        "id": "FdH0MNBkKcxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_input_token_length(message: str, chat_history: list[tuple[str, str]], system_prompt: str) -> None:\n",
        "    input_token_length = get_input_token_length(message, chat_history, system_prompt)\n",
        "    if input_token_length > MAX_INPUT_TOKEN_LENGTH:\n",
        "        raise gr.Error(f'The accumulated input is too long ({input_token_length} > {MAX_INPUT_TOKEN_LENGTH}). Clear your chat history and try again.')"
      ],
      "metadata": {
        "id": "HdZBK5VAKeWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "style = \"\"\"\n",
        "\n",
        "footer.svelte-1ax1toq.svelte-1ax1toq.svelte-1ax1toq {\n",
        "    display: None;\n",
        "    justify-content: center;\n",
        "    margin-top: var(--size-4);\n",
        "    color: Transparent\n",
        "}\n",
        ".dark {\n",
        "    --body-background-fill: rgba(0, 0, 0, 0.5);\n",
        "    --body-text-color: var(--neutral-100);\n",
        "    --color-accent-soft: var(--neutral-700);\n",
        "    --background-fill-primary: transparent;\n",
        "    --background-fill-secondary: transparent;\n",
        "    --border-color-accent: rgba(255 , 255 , 255 , 1);\n",
        "    --border-color-primary: rgba(255, 255, 255 , 0.02);\n",
        "    --link-text-color-active: var(--secondary-500);\n",
        "    --link-text-color: var(--secondary-500);\n",
        "    --link-text-color-hover: var(--secondary-400);\n",
        "    --link-text-color-visited: var(--secondary-600);\n",
        "    --body-text-color-subdued: var(--neutral-400);\n",
        "    --shadow-spread: 2px;\n",
        "    --block-background-fill: transparent;\n",
        "    --block-border-color: var(--border-color-primary);\n",
        "    --block-border-width: 2x;\n",
        "    --block-info-text-color: var(--body-text-color-subdued);\n",
        "    --block-label-background-fill: transparent;\n",
        "    --block-label-border-color: var(--border-color-primary);\n",
        "    --block_label_border_width: None;\n",
        "    --block-label-text-color: var(--neutral-200);\n",
        "    --block_shadow: #white;\n",
        "    --block_title_background_fill: None;\n",
        "    --block_title_border_color: None;\n",
        "    --block_title_border_width: None;\n",
        "    --block-title-text-color: var(--neutral-200);\n",
        "    --panel-background-fill: transparent;\n",
        "    --panel-border-color: var(--border-color-primary);\n",
        "    --panel_border_width: None;\n",
        "    --border-color-accent-subdued: var(--border-color-accent);\n",
        "    --chatbot-code-background-color: var(--neutral-800);\n",
        "    --checkbox-background-color: transparent;\n",
        "    --checkbox-background-color-focus: var(--checkbox-background-color);\n",
        "    --checkbox-background-color-hover: var(--checkbox-background-color);\n",
        "    --checkbox-background-color-selected: var(--secondary-600);\n",
        "    --checkbox-border-color: var(--neutral-700);\n",
        "    --checkbox-border-color-focus: var(--secondary-500);\n",
        "    --checkbox-border-color-hover: var(--neutral-600);\n",
        "    --checkbox-border-color-selected: var(--secondary-600);\n",
        "    --checkbox-border-width: var(--input-border-width);\n",
        "    --checkbox-label-background-fill: var(--button-secondary-background-fill);\n",
        "    --checkbox-label-background-fill-hover: var(--button-secondary-background-fill-hover);\n",
        "    --checkbox-label-background-fill-selected: var(--checkbox-label-background-fill);\n",
        "    --checkbox-label-border-color: var(--border-color-primary);\n",
        "    --checkbox-label-border-color-hover: var(--checkbox-label-border-color);\n",
        "    --checkbox-label-border-width: var(--input-border-width);\n",
        "    --checkbox-label-text-color: var(--body-text-color);\n",
        "    --checkbox-label-text-color-selected: var(--checkbox-label-text-color);\n",
        "    --error-background-fill: var(--background-fill-primary);\n",
        "    --error-border-color: #ef4444;\n",
        "    --error_border_width: None;\n",
        "    --error-text-color: #fef2f2;\n",
        "    --error-icon-color: #ef4444;\n",
        "    --input-background-fill: rgb(255 255 255 / 7%);\n",
        "    --input-background-fill-focus: rgb(255 255 255 / 18%);\n",
        "    --input-background-fill-hover: rgb(255 255 255 / 18%);\n",
        "    --input-border-color: rgb(255 255 255 / 28%);\n",
        "    --input-border-color-focus: rgb(168 168 168 / 87%);\n",
        "    --input-border-color-hover: rgb(255 255 255 / 44%);\n",
        "    --input_border_width: 2px;\n",
        "    --input-placeholder-color: rgb(255 255 255);\n",
        "    --input_shadow: 2px;\n",
        "    --input_shadow_focus: None;\n",
        "    --loader_color: None;\n",
        "    --slider_color: None;\n",
        "    --stat-background-fill: transparent;\n",
        "    --table-border-color: var(--neutral-700);\n",
        "    --table-even-background-fill: var(--neutral-700);\n",
        "    --table-odd-background-fill: var(--neutral-700);\n",
        "    --table-row-focus: var(--color-accent-soft);\n",
        "    --button-border-width: 1px;\n",
        "    --button-cancel-background-fill: var(--button-primary-background-fill);\n",
        "    --button-cancel-background-fill-hover: var(--button-primary-background-fill-hover);\n",
        "    --button-cancel-border-color: var(--button-secondary-border-color);\n",
        "    --button-cancel-border-color-hover: var(--button-cancel-border-color);\n",
        "    --button-cancel-text-color: var(--button-secondary-text-color);\n",
        "    --button-cancel-text-color-hover: var(--button-cancel-text-color);\n",
        "    --button-primary-background-fill: transparent;\n",
        "    --button-primary-background-fill-hover: #ffffff2e;\n",
        "    --button-primary-border-color: #ffffff;\n",
        "    --button-primary-border-color-hover: #ffffff;\n",
        "    --button-primary-text-color: #787878;\n",
        "    --button-primary-text-color-hover: white;\n",
        "    --button-secondary-background-fill: var(--button-primary-background-fill);\n",
        "    --button-secondary-background-fill-hover: #ffffff2e;\n",
        "    --button-secondary-border-color: #3b3b3b;\n",
        "    --button-secondary-border-color-hover: #ffffff;\n",
        "    --button-secondary-text-color: #787878;\n",
        "    --button-secondary-text-color-hover: #ffffff;\n",
        "    --name: glass;\n",
        "    --primary-50: rgba(250, 250, 250, 1);\n",
        "    --primary-100: rgba(245, 245, 245, 1);\n",
        "    --primary-200: rgba(235, 235, 235, 0.7);\n",
        "    --primary-300: rgba(220, 220, 220, 0.6);\n",
        "    --primary-400: rgba(168, 168, 168, 0.5);\n",
        "    --primary-500: rgba(0, 0, 0, 0);\n",
        "    --primary-600: rgba(0, 0, 0, 0);\n",
        "    --primary-700: rgb(68 68 68);\n",
        "    --primary-800: rgba(41, 41, 41, 0.2);\n",
        "    --primary-900: rgba(28, 28, 28, 0.1);\n",
        "    --primary-950: rgba(0, 0, 0, 0);\n",
        "    --secondary-50: rgba(250, 250, 250, 1);\n",
        "    --secondary-100: rgba(245, 245, 245, 1);\n",
        "    --secondary-200: rgba(235, 235, 235, 1);\n",
        "    --secondary-300: rgba(220, 220, 220, 1);\n",
        "    --secondary-400: rgba(168, 168, 168, 1);\n",
        "    --secondary-500: rgba(120, 120, 120, 1);\n",
        "    --secondary-600: rgb(0 0 0 / 0%);\n",
        "    --secondary-700: rgba(68, 68, 68, 0.1);\n",
        "    --secondary-800: rgb(41 41 41 / 0%);\n",
        "    --secondary-900: rgba(28, 28, 28, 1);\n",
        "    --secondary-950: rgba(15, 15, 15, 1);\n",
        "    --neutral-50: rgba(250, 250, 250, 1);\n",
        "    --neutral-100: rgba(245, 245, 245, 1);\n",
        "    --neutral-200: rgba(235, 235, 235, 1);\n",
        "    --neutral-300: rgba(220, 220, 220, 1);\n",
        "    --neutral-400: rgba(168, 168, 168, 1);\n",
        "    --neutral-500: rgba(120, 120, 120, 1);\n",
        "    --neutral-600: rgba(0, 0, 0, 0);\n",
        "    --neutral-700: rgba(68, 68, 68, 0);\n",
        "    --neutral-800: rgba(41, 41, 41, 1);\n",
        "    --neutral-900: rgba(28, 28, 28, 1);\n",
        "    --neutral-950: rgba(15, 15, 15, 1);\n",
        "    --spacing-xxs: 1px;\n",
        "    --spacing-xs: 1px;\n",
        "    --spacing-sm: 2px;\n",
        "    --spacing-md: 4px;\n",
        "    --spacing-lg: 6px;\n",
        "    --spacing-xl: 9px;\n",
        "    --spacing-xxl: 12px;\n",
        "    --radius-xxs: 1px;\n",
        "    --radius-xs: 1px;\n",
        "    --radius-sm: 2px;\n",
        "    --radius-md: 4px;\n",
        "    --radius-lg: 6px;\n",
        "    --radius-xl: 8px;\n",
        "    --radius-xxl: 12px;\n",
        "    --text-xxs: 8px;\n",
        "    --text-xs: 9px;\n",
        "    --text-sm: 11px;\n",
        "    --text-md: 13px;\n",
        "    --text-lg: 16px;\n",
        "    --text-xl: 20px;\n",
        "    --text-xxl: 24px;\n",
        "    --font: 'Optima', 'Candara', 'Noto Sans', 'source-sans-pro', sans-serif;\n",
        "    --font-mono: 'IBM Plex Mono', 'ui-monospace', 'Consolas', monospace;\n",
        "    --body-text-size: var(--text-md);\n",
        "    --body-text-weight: 400;\n",
        "    --embed-radius: var(--radius-lg);\n",
        "    --color-accent: var(--primary-500);\n",
        "    --shadow-drop: rgba(0,0,0,0.05) 0px 1px 2px 0px;\n",
        "    --shadow-drop-lg: 0 1px 3px 0 rgb(0 0 0 / 0.1), 0 1px 2px -1px rgb(0 0 0 / 0.1);\n",
        "    --shadow-inset: rgba(0,0,0,0.05) 0px 2px 4px 0px inset;\n",
        "    --block-info-text-size: var(--text-sm);\n",
        "    --block-info-text-weight: 400;\n",
        "    --block-label-border-width: 1px;\n",
        "    --block-label-shadow: var(--block-shadow);\n",
        "    --block-label-margin: 0;\n",
        "    --block-label-padding: var(--spacing-sm) var(--spacing-lg);\n",
        "    --block-label-radius: calc(var(--radius-lg) - 1px) 0 calc(var(--radius-lg) - 1px) 0;\n",
        "    --block-label-right-radius: 0 calc(var(--radius-lg) - 1px) 0 calc(var(--radius-lg) - 1px);\n",
        "    --block-label-text-size: var(--text-md);\n",
        "    --block-label-text-weight: 600;\n",
        "    --block-padding: var(--spacing-xl) calc(var(--spacing-xl) + 2px);\n",
        "    --block-radius: var(--radius-lg);\n",
        "    --block-shadow: var(--primary-400) 0px 0px 3px 0px;\n",
        "    --block-title-background-fill: none;\n",
        "    --block-title-border-color: none;\n",
        "    --block-title-border-width: 0px;\n",
        "    --block-title-padding: 0;\n",
        "    --block-title-radius: none;\n",
        "    --block-title-text-size: var(--text-md);\n",
        "    --block-title-text-weight: 600;\n",
        "    --container-radius: var(--radius-lg);\n",
        "    --form-gap-width: 0px;\n",
        "    --layout-gap: var(--spacing-xxl);\n",
        "    --panel-border-width: 1px;\n",
        "    --section-header-text-size: var(--text-md);\n",
        "    --section-header-text-weight: 400;\n",
        "    --checkbox-border-radius: var(--radius-sm);\n",
        "    --checkbox-label-gap: var(--spacing-lg);\n",
        "    --checkbox-label-padding: var(--spacing-md) calc(2 * var(--spacing-md));\n",
        "    --checkbox-label-shadow: none;\n",
        "    --checkbox-label-text-size: var(--text-md);\n",
        "    --checkbox-label-text-weight: 400;\n",
        "    --checkbox-check: url(data:image/svg+xml,%3csvg viewBox='0 0 16 16' fill='white' xmlns='http://www.w3.org/2000/svg'%3e%3cpath d='M12.207 4.793a1 1 0 010 1.414l-5 5a1 1 0 01-1.414 0l-2-2a1 1 0 011.414-1.414L6.5 9.086l4.293-4.293a1 1 0 011.414 0z'/%3e%3c/svg%3e);\n",
        "    --radio-circle: url(data:image/svg+xml,%3csvg viewBox='0 0 16 16' fill='white' xmlns='http://www.w3.org/2000/svg'%3e%3ccircle cx='8' cy='8' r='3'/%3e%3c/svg%3e);\n",
        "    --checkbox-shadow: var(--input-shadow);\n",
        "    --error-border-width: 1px;\n",
        "    --input-border-width: 2x;\n",
        "    --input-padding: var(--spacing-xl);\n",
        "    --input-radius: var(--radius-lg);\n",
        "    --input-shadow: none;\n",
        "    --input-shadow-focus: var(--input-shadow);\n",
        "    --input-text-size: var(--text-md);\n",
        "    --input-text-weight: 400;\n",
        "    --loader-color: var(--color-accent);\n",
        "    --prose-text-size: var(--text-md);\n",
        "    --prose-text-weight: 400;\n",
        "    --prose-header-text-weight: 600;\n",
        "    --slider-color: var(--primary-400);\n",
        "    --table-radius: var(--radius-lg);\n",
        "    --button-large-padding: var(--spacing-lg) calc(2 * var(--spacing-lg));\n",
        "    --button-large-radius: var(--radius-lg);\n",
        "    --button-large-text-size: var(--text-lg);\n",
        "    --button-large-text-weight: 600;\n",
        "    --button-shadow: none;\n",
        "    --button-shadow-active: var(--shadow-inset);\n",
        "    --button-shadow-hover: none;\n",
        "    --button-small-padding: var(--spacing-sm) calc(2 * var(--spacing-sm));\n",
        "    --button-small-radius: var(--radius-lg);\n",
        "    --button-small-text-size: var(--text-md);\n",
        "    --button-small-text-weight: 400;\n",
        "    --button-transition: background-color 0.2s ease;\n",
        "}\n",
        "    .chatbot {\n",
        "        display: flex;\n",
        "        flex-direction: column;\n",
        "        align-items: flex-start;\n",
        "    }\n",
        "\n",
        "    .chatbot .bubble {\n",
        "        margin-left: 10px;\n",
        "    }\n",
        "\n",
        "    .chatbot .bubble .content {\n",
        "        max-width: 60%;\n",
        "    }\n",
        "\n",
        "    .user {\n",
        "        display: flex;\n",
        "        flex-direction: column;\n",
        "        align-items: flex-end;\n",
        "    }\n",
        "\n",
        "    .user .bubble {\n",
        "        margin-right: 10px;\n",
        "    }\n",
        "\n",
        "    .user .bubble .content {\n",
        "        max-width: 60%;\n",
        "    }\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "YxgYfHCDKiEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(css=style) as demo:\n",
        "    system_prompt = gr.Textbox(label='System:',\n",
        "                              value=DEFAULT_SYSTEM_PROMPT,\n",
        "                              lines=0,visible=False)\n",
        "    with gr.Group():\n",
        "        chatbot = gr.Chatbot(label='FAQ',bubble_full_width=True)\n",
        "        with gr.Row():\n",
        "            textbox = gr.Textbox(\n",
        "                container=False,\n",
        "                show_label=False,\n",
        "                scale=4,\n",
        "            )\n",
        "            submit_button = gr.Button('Send',\n",
        "                                      variant='primary',\n",
        "                                      scale=1,\n",
        "                                      min_width=0)\n",
        "\n",
        "    saved_input = gr.State()\n",
        "\n",
        "    textbox.submit(\n",
        "        fn=clear_and_save_textbox,\n",
        "        inputs=textbox,\n",
        "        outputs=[textbox, saved_input],\n",
        "        api_name=False,\n",
        "        queue=False,\n",
        "    ).then(\n",
        "        fn=display_input,\n",
        "        inputs=[saved_input, chatbot],\n",
        "        outputs=chatbot,\n",
        "        api_name=False,\n",
        "        queue=False,\n",
        "    ).then(\n",
        "        fn=check_input_token_length,\n",
        "        inputs=[saved_input, chatbot, system_prompt],\n",
        "        api_name=False,\n",
        "        queue=False,\n",
        "    ).success(\n",
        "        fn=generate,\n",
        "        inputs=[\n",
        "            saved_input,\n",
        "            chatbot,\n",
        "            system_prompt,\n",
        "        ],\n",
        "        outputs=chatbot,\n",
        "        api_name=False,\n",
        "    )\n",
        "\n",
        "    button_event_preprocess = submit_button.click(\n",
        "        fn=clear_and_save_textbox,\n",
        "        inputs=textbox,\n",
        "        outputs=[textbox, saved_input],\n",
        "        api_name=False,\n",
        "        queue=False,\n",
        "    ).then(\n",
        "        fn=display_input,\n",
        "        inputs=[saved_input, chatbot],\n",
        "        outputs=chatbot,\n",
        "        api_name=False,\n",
        "        queue=False,\n",
        "    ).then(\n",
        "        fn=check_input_token_length,\n",
        "        inputs=[saved_input, chatbot, system_prompt],\n",
        "        api_name=False,\n",
        "        queue=False,\n",
        "    ).success(\n",
        "        fn=generate,\n",
        "        inputs=[\n",
        "            saved_input,\n",
        "            chatbot,\n",
        "            system_prompt,\n",
        "        ],\n",
        "        outputs=chatbot,\n",
        "        api_name=False,\n",
        "    )"
      ],
      "metadata": {
        "id": "j45ab79MKlIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.queue(max_size=20).launch(inline=True,share=True,debug=True)"
      ],
      "metadata": {
        "id": "rtwbqcjFKn-n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}